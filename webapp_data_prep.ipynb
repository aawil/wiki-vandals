{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the previously prepared dataset of 730,000 anonymous English Wikipedia revisions (May 4 - June 4) and creates the dataframes used in the [Local Vandals](localvandals.herokuapp.com) web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "changes = pd.read_csv('changes.csv').drop(['Unnamed: 0', 'latlng'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes['rc_title'] = changes['rc_title'].map(lambda x: str(x).translate(str.maketrans(\"_\", \" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three functions below do most of the work here. All of them take in a dataframe, a geographic unit (that is, the name of the column with the desired grouping unit: e.g., 'country') and a cutoff for the minimum number of revisions per geographical unit. The top-articles and top-vandalized functions also have a parameter for the number of top articles required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_damage_pct_diff(df, unit, minimum):\n",
    "    counts = df[unit].value_counts()\n",
    "    selection = df[df[unit].isin(counts[counts >= minimum].index)]\n",
    "    mean_damage = selection['damage_prob'].mean()\n",
    "    unit_damage_df = selection.groupby(unit, as_index=False)['damage_prob'].mean()\n",
    "    pct_diff = round(\n",
    "        ((unit_damage_df['damage_prob'] - mean_damage)/unit_damage_df['damage_prob']) * 100)\n",
    "    unit_damage_df['pct_diff'] = pct_diff\n",
    "    unit_damage_df = unit_damage_df.set_index(unit).drop('damage_prob', axis=1)\n",
    "    return unit_damage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(df, unit, minimum, n_articles=5):\n",
    "    counts = df[unit].value_counts()\n",
    "    selection = df[df[unit].isin(counts[counts >= minimum].index)]\n",
    "    top_articles = selection.groupby(unit)['rc_title'].value_counts()\n",
    "    top_n = top_articles.groupby(level=[0]).nlargest(n_articles)\n",
    "    top_n.index = top_n.index.droplevel(0)\n",
    "    top_n = top_n.index.to_frame().reset_index(drop=True)\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_vandalized(df, unit, minimum, n_articles=5):\n",
    "    counts = df[unit].value_counts()\n",
    "    selection = df[df[unit].isin(counts[counts >= minimum].index)]\n",
    "    vandalized = selection[selection['damage_prob'] > 0.9]\n",
    "    top_articles = vandalized.groupby(unit)['rc_title'].value_counts()\n",
    "    top_n = top_articles.groupby(level=[0]).nlargest(n_articles)\n",
    "    top_n.index = top_n.index.droplevel(0)\n",
    "    top_n = top_n.index.to_frame().reset_index(drop=True)\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_damage = get_damage_pct_diff(changes, 'country', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_iso_damage = get_damage_pct_diff(changes, 'country_iso', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('country_iso_damage.pkl', 'wb') as f:\n",
    "    pickle.dump(country_iso_damage, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_us = changes.query('country_iso == \"US\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some zip codes got mangled in the pandas import - let's fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize_zip(zipcode):\n",
    "    try:\n",
    "        code = str(int(zipcode))\n",
    "    except ValueError:\n",
    "        return None\n",
    "    code = code.zfill(5)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "changes_us['postcode'] = changes_us['postcode'].map(regularize_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_damage = get_damage_pct_diff(changes_us, 'state', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't use 'city' by itself: e.g., Springfield, IL and Springfield, MA are two different places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "changes_us['citystate'] = changes_us['city'] + \", \" + changes_us['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2931"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_damage = get_damage_pct_diff(changes_us, 'citystate', 10)\n",
    "len(city_damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5205"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_damage = get_damage_pct_diff(changes_us, 'postcode', 10)\n",
    "len(zip_damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "geog_damage = pd.concat([country_damage, state_damage, city_damage, zip_damage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_top_articles = country_top_articles.set_index('country')\n",
    "state_top_articles = state_top_articles.set_index('state')\n",
    "city_top_articles = city_top_articles.set_index('citystate')\n",
    "zip_top_articles = zip_top_articles.set_index('postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "geog_top_articles = pd.concat([country_top_articles, state_top_articles,\n",
    "                               city_top_articles, zip_top_articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_top_vandalized = country_top_vandalized.set_index('country')\n",
    "state_top_vandalized = state_top_vandalized.set_index('state')\n",
    "city_top_vandalized = city_top_vandalized.set_index('citystate')\n",
    "zip_top_vandalized = zip_top_vandalized.set_index('postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "geog_top_vandalized = pd.concat([country_top_vandalized, state_top_vandalized,\n",
    "                                city_top_vandalized, zip_top_vandalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "geog_damage.to_pickle('geog_damage.pkl')\n",
    "geog_top_articles.to_pickle('geog_top_articles.pkl')\n",
    "geog_top_vandalized.to_pickle('geog_top_vandalized.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
